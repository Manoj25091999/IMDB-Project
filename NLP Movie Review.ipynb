{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Untitled8.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "6ZFHLWeLnAzL",
        "jYDHQMpvZDgn",
        "RSOinfWspOlF",
        "tMuRZ5m1pide"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFwVSqH8ezif"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "import re\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufJtDZpZkbOc"
      },
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/IMDB Project/IMDB Dataset.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "z8a-zl3bkbaZ",
        "outputId": "df5d7edb-df1d-4057-8db0-10a77ebc3ba1"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "lBq_QLNBkbkd",
        "outputId": "62b842da-352d-48f8-c93d-e8dd97e6fef2"
      },
      "source": [
        "data.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>I thought this movie did a down right good job...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>I am a Catholic taught in parochial elementary...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>I'm going to have to disagree with the previou...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>No one expects the Star Trek movies to be high...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  review sentiment\n",
              "49995  I thought this movie did a down right good job...  positive\n",
              "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
              "49997  I am a Catholic taught in parochial elementary...  negative\n",
              "49998  I'm going to have to disagree with the previou...  negative\n",
              "49999  No one expects the Star Trek movies to be high...  negative"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFM43K9U_au7",
        "outputId": "84caa6d6-caec-4318-d113-a01cc9abbaa8"
      },
      "source": [
        "# Checking null values\r\n",
        "data.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "review       0\n",
              "sentiment    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hJ2z-62_gnQ",
        "outputId": "7f6bafe5-3bfd-4de5-ba73-0575ac15fef5"
      },
      "source": [
        "data.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 50000 entries, 0 to 49999\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   review     50000 non-null  object\n",
            " 1   sentiment  50000 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 781.4+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgfX9FR0_DAh"
      },
      "source": [
        "Dividing the datasets for analysis and modelling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXAlb4Ah-klq"
      },
      "source": [
        "Y = data['sentiment']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssM-e7h8-V2U"
      },
      "source": [
        "X = data.drop(['sentiment'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmyQqAh3_Ole",
        "outputId": "63730823-1846-4c35-f15a-2035e3d1ea94"
      },
      "source": [
        "X.shape, Y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 1), (50000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "am0asohDkbsB",
        "outputId": "4bb117ca-c9d0-4ad6-9a40-6e4890cce816"
      },
      "source": [
        "Y.value_counts(normalize=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "negative    0.5\n",
              "positive    0.5\n",
              "Name: sentiment, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7SqxwoDkyyn"
      },
      "source": [
        "Y.replace({'positive':1, 'negative':0}, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnS2W64okzAb"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTj_y-n_lmbR",
        "outputId": "20267a1c-74e7-4095-fc4f-a3477b92ee6a"
      },
      "source": [
        "pip install nltk"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BB8Wa01Elmfb",
        "outputId": "3543808f-a994-4583-cf7a-c750c2f78123"
      },
      "source": [
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\r\n",
        "from nltk.corpus import stopwords\r\n",
        "import nltk\r\n",
        "nltk.download('stopwords')\r\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5QkYDE1pIHN"
      },
      "source": [
        "ps = PorterStemmer()\r\n",
        "lt = WordNetLemmatizer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dv2WcAiZpW7i"
      },
      "source": [
        "# Removing the stopwords\r\n",
        "corpus = []\r\n",
        "for i in range(0,len(X)):\r\n",
        "  review = re.sub(\"[^a-zA-Z]\", \" \", X['review'][i])\r\n",
        "  review = review.lower()\r\n",
        "  review = review.split()\r\n",
        "  review = [lt.lemmatize(word) for word in review if not word in stopwords.words('english')]\r\n",
        "  review = \" \".join(review)\r\n",
        "  corpus.append(review)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmNKpFse3_62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "outputId": "df9cd2c1-c950-4973-c728-44815f1d2be0"
      },
      "source": [
        "X['review'][1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams\\' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master\\'s of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional \\'dream\\' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell\\'s murals decorating every surface) are terribly well done.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5IzJn1NgZA2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "b91fa297-841f-40e4-f255-4655471710eb"
      },
      "source": [
        "corpus[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'wonderful little production br br filming technique unassuming old time bbc fashion give comforting sometimes discomforting sense realism entire piece br br actor extremely well chosen michael sheen got polari voice pat truly see seamless editing guided reference williams diary entry well worth watching terrificly written performed piece masterful production one great master comedy life br br realism really come home little thing fantasy guard rather use traditional dream technique remains solid disappears play knowledge sens particularly scene concerning orton halliwell set particularly flat halliwell mural decorating every surface terribly well done'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLYzuh3HmE2X"
      },
      "source": [
        "# Vectorzing the words\r\n",
        "Vect = TfidfVectorizer(max_features=5000, ngram_range=(1,3))\r\n",
        "X = Vect.fit_transform(corpus).toarray()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oek1D77l4fU8"
      },
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IM1WcuAhAqhh"
      },
      "source": [
        "# Spliiting the dataset for modelling\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vHd14zdAq_q"
      },
      "source": [
        "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iBHekcdArIq"
      },
      "source": [
        "Vect.get_feature_names()[:50]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bibTq3VWHj8R"
      },
      "source": [
        "Vect.get_params()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Rw7q0fDHUD4"
      },
      "source": [
        "Checking the training dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDV9ZojFArNK"
      },
      "source": [
        "final_df = pd.DataFrame(x_train, columns = Vect.get_feature_names())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gS5F0jcTArRz"
      },
      "source": [
        "final_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGhVpEB0ArWg"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.svm import SVC\r\n",
        "\r\n",
        "classifier_1 = SVC() \r\n",
        "classifier_2 = MultinomialNB()\r\n",
        "classifier_3 = LogisticRegression()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZmOKc6aBWya"
      },
      "source": [
        "classifier_2.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HY-G85Ujs5IQ"
      },
      "source": [
        "x_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCyCo5rqebYh"
      },
      "source": [
        "pred2 = classifier_2.predict(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIdptulARl-o"
      },
      "source": [
        "pred2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "os2zg54M4ph7"
      },
      "source": [
        "pred_prob = classifier_2.predict_proba(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0if8Usydejzb"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzckm8pt4rOp"
      },
      "source": [
        "print(\"Accuracy score with Multinomial Naive Bayes : {:.4f}\".format(accuracy_score(y_test,pred2)))\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6XnSKHYtB_-"
      },
      "source": [
        "print(\"The classification_report:\")\r\n",
        "print(classification_report(y_test,pred2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbpzNdViuPMP"
      },
      "source": [
        "precision_score(y_test, pred2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoopiAPHumTn"
      },
      "source": [
        "confusion_matrix(y_test, pred2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DMTby47bEAI"
      },
      "source": [
        "classifier_3.fit(x_train,y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmC9NSgxTOSu"
      },
      "source": [
        "pred3 = classifier_3.predict(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qx7oWh3nTj-u"
      },
      "source": [
        "accuracy_score(y_test,pred3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ph8isk75TnEX"
      },
      "source": [
        "pred_prob = classifier_3.predict_proba(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXfmsADlT2cP"
      },
      "source": [
        "pred_prob"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYtia2pbeP6h"
      },
      "source": [
        "Checking the metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1lM9RjqhA4D"
      },
      "source": [
        "\r\n",
        "# Function to calculate Precision and Recall\r\n",
        "\r\n",
        "def calc_precision_recall(y_true, y_pred):\r\n",
        "    \r\n",
        "    # Convert predictions to series with index matching y_true\r\n",
        "    y_pred = pd.Series(y_pred, index=y_true.index)\r\n",
        "    \r\n",
        "    # Instantiate counters\r\n",
        "    TP = 0\r\n",
        "    FP = 0\r\n",
        "    FN = 0\r\n",
        "\r\n",
        "    # Determine whether each prediction is TP, FP, TN, or FN\r\n",
        "    for i in y_true.index: \r\n",
        "        if y_true[i]==y_pred[i]==1:\r\n",
        "           TP += 1\r\n",
        "        if y_pred[i]==1 and y_true[i]!=y_pred[i]:\r\n",
        "           FP += 1\r\n",
        "        if y_pred[i]==0 and y_test[i]!=y_pred[i]:\r\n",
        "           FN += 1\r\n",
        "    \r\n",
        "    # Calculate true positive rate and false positive rate\r\n",
        "    # Use try-except statements to avoid problem of dividing by 0\r\n",
        "    try:\r\n",
        "        precision = TP / (TP + FP)\r\n",
        "    except:\r\n",
        "        precision = 1\r\n",
        "    \r\n",
        "    try:\r\n",
        "        recall = TP / (TP + FN)\r\n",
        "    except:\r\n",
        "        recall = 1\r\n",
        "\r\n",
        "    return precision, recall"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KniTgjDnAIf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZFHLWeLnAzL"
      },
      "source": [
        "# Checking the thresholds for better prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYDHQMpvZDgn"
      },
      "source": [
        "lr_proba = pred_prob[:,1]\r\n",
        "\r\n",
        "# Defining probability thresholds to use between 0 and 1\r\n",
        "#prob_thres = np.linspace(0,1,num=100)\r\n",
        "\r\n",
        "x_test_pred=[]\r\n",
        "  \r\n",
        "for l in lr_proba:\r\n",
        "  if l>0.50:\r\n",
        "   x_test_pred.append(1)\r\n",
        "  if l<0.50:\r\n",
        "   x_test_pred.append(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4O2TaWgyjWcO"
      },
      "source": [
        "accuracy_score(y_test,x_test_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpZrK9crj1S8"
      },
      "source": [
        "print(classification_report(y_test,x_test_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRsMP-j2k_lx"
      },
      "source": [
        "confusion_matrix(y_test, x_test_pred, labels=[0,1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlaaKGuuipzc"
      },
      "source": [
        "from sklearn.metrics import plot_precision_recall_curve\r\n",
        "\r\n",
        "plot_precision_recall_curve(classifier_3, x_test, y_test, name = 'Logistic Regression');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSOinfWspOlF"
      },
      "source": [
        "# Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYHkU1b3oYfd"
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV, RandomizedSearchCV\r\n",
        "from sklearn.linear_model import LogisticRegressionCV\r\n",
        "\r\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=17)\r\n",
        "param_grid = {\"C\":np.logspace(-2,3,500), \"penalty\":['l1','l2'], 'solver':['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'max_iter':[200]}\r\n",
        "\r\n",
        "tuned_logit = RandomizedSearchCV(classifier_3, param_grid , cv=skf, random_state=17)\r\n",
        "tuned_logit.fit(x_train,y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wtf0Scj8wa7"
      },
      "source": [
        "tuned_logit.best_params_, tuned_logit.best_score_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMuRZ5m1pide"
      },
      "source": [
        "#tuned_logit.C_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "757fnyr1ugPs"
      },
      "source": [
        "p = tuned_logit.predict(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHnYNR4yvC0L"
      },
      "source": [
        "accuracy_score(y_test, p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtXotjsnpGbg"
      },
      "source": [
        "q = tuned_logit.predict_proba(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9aJiecLvFbK"
      },
      "source": [
        "lr_proba_2 = q[:,1]\r\n",
        "\r\n",
        "# Defining probability thresholds to use between 0 and 1\r\n",
        "#prob_thres = np.linspace(0,1,num=100)\r\n",
        "\r\n",
        "x_test_pred_2=[]\r\n",
        "  \r\n",
        "for l in lr_proba_2:\r\n",
        "  if l>0.50:\r\n",
        "   x_test_pred_2.append(1)\r\n",
        "  if l<0.50:\r\n",
        "   x_test_pred_2.append(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gz4bgpIUpRW1"
      },
      "source": [
        "accuracy_score(y_test, x_test_pred_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVEHUyWjpWzy"
      },
      "source": [
        "print(classification_report(y_test, x_test_pred_2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzChQ5YYqBd0"
      },
      "source": [
        "## Using Bidirectional RNN with LSTM using word embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhWUcpByR9zX"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import one_hot\r\n",
        "from tensorflow.keras.layers import Embedding\r\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hul7BRJu3Xhq"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvEpKp5eR_pd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89021bb4-7c02-4276-f191-47ecdcc8d846"
      },
      "source": [
        "# Converting sentences in corpus into a one_hot feature vector\r\n",
        "one_hot_repr = [one_hot(sent,10000) for sent in corpus]\r\n",
        "print(one_hot_repr[0]) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[8695, 6292, 2260, 5915, 4876, 3681, 2723, 3791, 305, 6065, 8107, 8107, 2634, 2499, 7248, 4876, 7274, 6230, 7023, 7326, 2847, 3791, 300, 7536, 9373, 153, 3552, 684, 1638, 153, 9600, 199, 404, 285, 3227, 7326, 4493, 7501, 5546, 300, 8107, 8107, 52, 4876, 2981, 5179, 4183, 539, 7010, 2477, 3575, 3426, 162, 4893, 7421, 2912, 8256, 2603, 117, 5615, 6571, 5783, 6870, 5904, 5607, 9149, 581, 7421, 2871, 1133, 6399, 33, 6441, 3031, 7816, 4009, 3029, 8999, 9338, 1903, 9135, 8999, 3470, 9025, 7915, 5799, 3266, 8107, 8107, 1287, 7386, 9072, 3559, 153, 9232, 8710, 7536, 153, 9235, 5344, 9842, 8218, 8554, 5973, 426, 5344, 1423, 5344, 6896, 4876, 9995, 4378, 2634, 3681, 5584, 3760, 7248, 3872, 2160, 7386, 8716, 2462, 8178, 8081, 4876, 1332, 882, 5607, 360, 4187, 7326, 7326, 5482, 2086, 6873, 292, 4137, 5409, 4829, 7024, 9478, 3266, 5557, 5210, 3741, 7418, 5409, 843, 2603, 1715, 9232, 1447, 1669, 1234, 2603, 9859, 5915, 4876, 6398, 1370, 36, 725, 486, 1966, 9478, 2104, 6009, 3735]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cy7EUWU-O8t7"
      },
      "source": [
        "with open('one_hot_transform.pkl', 'wb') as f:\r\n",
        "  pickle.dump(one_hot_repr,f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tnq5oUqZR_wW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82cdc8b9-9f56-4a5f-9faf-f6c86b900857"
      },
      "source": [
        "# Making each sentence into same length\r\n",
        "sent_length = len(max(corpus, key=len)) #Finding the max length of a string in corpus\r\n",
        "embedded_repr = pad_sequences(one_hot_repr, padding='pre', maxlen=sent_length)\r\n",
        "print(embedded_repr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[   0    0    0 ... 2104 6009 3735]\n",
            " [   0    0    0 ... 3079 5557 7268]\n",
            " [   0    0    0 ... 7536 2824 2287]\n",
            " ...\n",
            " [   0    0    0 ... 5328 4327 9364]\n",
            " [   0    0    0 ... 4591 2257  567]\n",
            " [   0    0    0 ... 7959 1073 2122]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ja0MY3lAR_1U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bde81983-5126-40bc-e1e2-bea8b2fb21c5"
      },
      "source": [
        "embedded_repr[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    0,    0, ..., 2104, 6009, 3735], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FomYacbcPWTd"
      },
      "source": [
        "pickle.dump(embedded_repr, open('embedded_repr.pkl','wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doYxzPXCof8t"
      },
      "source": [
        "## Modelling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJ-ztGKPkhFi"
      },
      "source": [
        "from tensorflow.keras.layers import Dense, Flatten, Dropout"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aAf8lqE31jI"
      },
      "source": [
        "from tensorflow.keras import layers\r\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHJ3KD1vo0Jd"
      },
      "source": [
        "model = Sequential()\r\n",
        "# Adding Word Embedding layer\r\n",
        "model.add(Embedding(10000,10, input_length=sent_length))\r\n",
        "# Adding Bidirectional LSTM layer\r\n",
        "model.add(layers.Bidirectional(layers.LSTM(100)))\r\n",
        "# Adding output layer\r\n",
        "model.add(Dense(units=1, kernel_initializer='glorot_uniform', activation='sigmoid'))\r\n",
        "# Comipiling the model (adding optimizer, loss function, and required metrics)\r\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-YQamfJtRIm"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3z5gTLoSk6eM"
      },
      "source": [
        "X_final = np.array(embedded_repr)\r\n",
        "Y_final = np.array(Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-bj1NtNlJnr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5646a263-522f-4385-bb39-890606921c54"
      },
      "source": [
        "X_final.shape, Y_final.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 9168), (50000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kN3GMLUBA90J"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_final, Y_final, test_size=0.33)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0LPkoMHtUt4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd5032d4-42ed-4907-b043-828fbbfc85a7"
      },
      "source": [
        "# Fitting the model\r\n",
        "model_history = model.fit(x_train, y_train, validation_data=(x_test,y_test), batch_size=128, epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "262/262 [==============================] - 321s 1s/step - loss: 0.6088 - accuracy: 0.6513 - val_loss: 0.3616 - val_accuracy: 0.8505\n",
            "Epoch 2/10\n",
            "262/262 [==============================] - 317s 1s/step - loss: 0.2848 - accuracy: 0.8872 - val_loss: 0.3032 - val_accuracy: 0.8734\n",
            "Epoch 3/10\n",
            "262/262 [==============================] - 317s 1s/step - loss: 0.2196 - accuracy: 0.9181 - val_loss: 0.3176 - val_accuracy: 0.8722\n",
            "Epoch 4/10\n",
            "262/262 [==============================] - 316s 1s/step - loss: 0.1963 - accuracy: 0.9293 - val_loss: 0.3305 - val_accuracy: 0.8671\n",
            "Epoch 5/10\n",
            "262/262 [==============================] - 317s 1s/step - loss: 0.1728 - accuracy: 0.9402 - val_loss: 0.3532 - val_accuracy: 0.8666\n",
            "Epoch 6/10\n",
            "262/262 [==============================] - 315s 1s/step - loss: 0.1507 - accuracy: 0.9484 - val_loss: 0.3523 - val_accuracy: 0.8625\n",
            "Epoch 7/10\n",
            "262/262 [==============================] - 315s 1s/step - loss: 0.1301 - accuracy: 0.9566 - val_loss: 0.4494 - val_accuracy: 0.8596\n",
            "Epoch 8/10\n",
            "262/262 [==============================] - 316s 1s/step - loss: 0.1231 - accuracy: 0.9601 - val_loss: 0.4192 - val_accuracy: 0.8588\n",
            "Epoch 9/10\n",
            "262/262 [==============================] - 315s 1s/step - loss: 0.1083 - accuracy: 0.9674 - val_loss: 0.4495 - val_accuracy: 0.8541\n",
            "Epoch 10/10\n",
            "262/262 [==============================] - 316s 1s/step - loss: 0.0984 - accuracy: 0.9676 - val_loss: 0.4906 - val_accuracy: 0.8527\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbwBkv2Atjs_"
      },
      "source": [
        "# Saving the model\r\n",
        "model.save('nlp1_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ogeXoDWhq-L"
      },
      "source": [
        "from tensorflow.keras.models import load_model\r\n",
        "\r\n",
        "model_3 = load_model('nlp1_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mcM77sfQJF1"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kQRVOco8LMa"
      },
      "source": [
        "sent = ['The movie is good']\r\n",
        "\r\n",
        "one_hot_repr_2 = [one_hot(sent,10000) for sent in sent]\r\n",
        "\r\n",
        "sent_length_2 = len(max(sent, key=len)) #Finding the max length of a string in corpus\r\n",
        "embedded_repr_2 = pad_sequences(one_hot_repr_2, padding='pre', maxlen=9168)\r\n",
        "\r\n",
        "sent_final = np.array(embedded_repr_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcwDd-wp2y2y"
      },
      "source": [
        "pred = model_3.predict(sent_final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CGZduNB78UA"
      },
      "source": [
        "pred = (pred>0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vBUAZB9PnMw",
        "outputId": "be7a1a02-0dae-406f-d85c-ebd1ce778eb7"
      },
      "source": [
        "pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ True]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Q-4QZ2S72-a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}